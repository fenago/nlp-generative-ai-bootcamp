{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Top Keywords from the news article\n",
    "In this notebook, we will perform the activity of extracting top keywords from news article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ankit.bhatia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk import download, stem\n",
    "\n",
    "# The below statement will download the stop word list\n",
    "# 'nltk_data/corpora/stopwords/' at home directory of your computer\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    news = ''.join([line for line in open(file_path,encoding='utf-8')])\n",
    "    return news\n",
    "\n",
    "# This method will take string as input and return the string\n",
    "#  converted into lowercase\n",
    "def to_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "# This will take a text string as input and return the token.\n",
    "wht = WhitespaceTokenizer()\n",
    "def tokenize_text(text):\n",
    "    return wht.tokenize(text=text)\n",
    "\n",
    "# This will remove stop word tokens from the token list.\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stop_words(token_list):\n",
    "    return [word for word in token_list if word not in stop_words]\n",
    "\n",
    "\n",
    "# This will take a token list as input and return stemmed token list\n",
    "stemmer = stem.PorterStemmer()\n",
    "def get_stems(token_list):\n",
    "    return [stemmer.stem(word) for word in token_list]\n",
    "\n",
    "# This method will generate a dict of word frequencies from list.\n",
    "def get_freq(stems):\n",
    "    freq_dict = {}\n",
    "    for t in stems:\n",
    "        freq_dict[t.strip()] = freq_dict.get(t.strip(), 0) + 1\n",
    "    return freq_dict\n",
    "\n",
    "# This method will sort the dictionary on the values and return the top n \n",
    "# keys of the dictionary.\n",
    "def get_top_n_words(freq_dict, n):\n",
    "    sorted_dict = sorted(freq_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return [x[0] for x in sorted_dict][:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/news_article.txt\"\n",
    "news_article = load_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case_news_art = to_lower_case(text=news_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_text(lower_case_news_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_tokens = remove_stop_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = get_stems(removed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = get_freq(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['law', 'justic', 'european', 'parti', 'took', 'polandâ€™']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_keywords = get_top_n_words(freq_dict, 6)\n",
    "top_keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
