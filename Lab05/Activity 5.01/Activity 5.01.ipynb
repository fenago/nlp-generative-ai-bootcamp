{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeopardy Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JEOPARDY_CSV =  '../data/jeopardy/Jeopardy.csv'\n",
    "\n",
    "questions = pd.read_csv(JEOPARDY_CSV)\n",
    "\n",
    "questions.columns = [x.strip() for x in questions.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.dropna(subset=['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions['Category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='../data/jeopardy/JQuestions.txt'\n",
    "questions['Question'].sample(frac=0.04,replace=False,random_state=0).to_csv(file)\n",
    "\n",
    "f=open(file,'r',encoding='utf-8')\n",
    "text=f.read()\n",
    "f.close()\n",
    "\n",
    "doc=nlp(text)\n",
    "pos_list=['NOUN']\n",
    "preproc_text=[]\n",
    "preproc_sent=[]\n",
    "\n",
    "for token in doc:\n",
    "    if token.text!='\\n':\n",
    "        if not(token.is_stop) and not(token.is_punct) and token.pos_ in pos_list:\n",
    "            preproc_sent.append(token.lemma_)\n",
    "    else:\n",
    "        preproc_text.append(preproc_sent)\n",
    "        preproc_sent=[]\n",
    "\n",
    "preproc_text.append(preproc_sent) #last sentence\n",
    "\n",
    "print(preproc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "NUM_TOPICS=1000\n",
    "\n",
    "mdl = tp.LDAModel(k=NUM_TOPICS,seed=1234)\n",
    "\n",
    "for line in preproc_text:\n",
    "    mdl.add_doc(line)\n",
    "    \n",
    "mdl.train(10)\n",
    "    \n",
    "for k in range(mdl.k):\n",
    "    print('Top 7 words of topic #{}'.format(k))\n",
    "    print(mdl.get_topic_words(k, top_n=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log perplexity=',mdl.ll_per_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bag_of_words=[word for sent in preproc_text for word in sent]\n",
    "doc_inst = mdl.make_doc(bag_of_words)\n",
    "np.argsort(np.array(mdl.infer(doc_inst)[0]))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mdl.get_topic_words(461, top_n=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mdl.get_topic_words(234, top_n=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mdl.get_topic_words(186, top_n=7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
